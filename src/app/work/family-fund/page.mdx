import logo from '@/images/clients/family-fund/logomark-dark.svg'
import imageHero from './hero.jpg'
import imageDebraFiscal from './debra-fiscal.jpg'

export const caseStudy = {
client: 'DataStream Inc.',
  title: 'Revolutionizing data flows for real-time analytics',
  description:
    'DataStream Inc. is a cutting-edge tech company that needed a robust data architecture to handle their real-time analytics needs. Syyft delivered a scalable, efficient ETL solution that transformed their data processing capabilities.',
  summary: [
    'DataStream Inc. required a high-performance data pipeline to process and analyze millions of data points in real-time from IoT devices.',
    'We developed a custom ETL solution using Apache Kafka and Apache Spark, integrating with their existing data warehouse to enable real-time analytics and reporting.',
  ],
  logo,
  image: { src: imageHero },
  date: '2023-01',
  service: 'Web development, CMS',
  testimonial: {
    author: { name: 'Debra Fiscal', role: 'CEO of FamilyFund' },
    content:
      'Working with Syyft, we felt more like a partner than a customer. they revolutionized our entire data infrastructure.',
  },
}

export const metadata = {
  title: `${caseStudy.client} Case Study`,
  description: caseStudy.description,
}

## Overview

DataStream Inc. came to us with a challenging problem: they needed to process and analyze data from millions of IoT devices in real-time. Their existing infrastructure was buckling under the load, causing delays in insights and missed opportunities.

We proposed a complete overhaul of their data architecture, centered around a high-performance ETL pipeline. Our solution leveraged Apache Kafka for real-time data ingestion and Apache Spark for distributed data processing.

To ensure seamless integration with their existing systems, we implemented a custom data lake solution using Delta Lake, providing ACID transactions and time travel capabilities. This allowed DataStream Inc. to maintain historical data while enabling real-time analytics.

We also implemented advanced data governance and quality checks throughout the pipeline, ensuring that the data powering their analytics was always accurate and compliant with industry regulations.

## What we did

<TagList>
  <TagListItem>Data Architecture Design</TagListItem>
  <TagListItem>ETL Pipeline Development</TagListItem>
  <TagListItem>Real-time Analytics Integration</TagListItem>
  <TagListItem>Data Governance Implementation</TagListItem>
</TagList>

<Blockquote
  author={{ name: 'Jane Data', role: 'CTO of DataStream Inc.' }}
  image={{ src: imageDebraFiscal }}
>
  Syyft didn't just deliver a solution; they revolutionized our entire data infrastructure. Their expertise in building scalable data architectures and efficient ETL processes has given us capabilities we didn't think were possible.
</Blockquote>

<StatList>
  <StatListItem value="99.99%" label="Data pipeline uptime" />
  <StatListItem value="100x" label="Increase in data processing speed" />
  <StatListItem value="60%" label="Reduction in data storage costs" />
  <StatListItem value="15 min" label="From raw data to actionable insights" />
</StatList>
